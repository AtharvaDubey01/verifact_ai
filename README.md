# ğŸ›¡ï¸ CrisisGuard AI - Real-Time Misinformation Detection Platform

**A production-ready AI-powered fact-verification system** built for hackathons and real-world deployment.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11-blue.svg)
![React](https://img.shields.io/badge/react-18.2-blue.svg)

---

## ğŸ“‹ Overview

CrisisGuard AI (aka VeriFacts) is a complete misinformation detection and verification platform that:

- âœ… **Detects claims** in text using AI
- âœ… **Retrieves evidence** from multiple authoritative sources
- âœ… **Fact-checks claims** with LLM reasoning agents
- âœ… **Clusters similar claims** to identify viral misinformation
- âœ… **Provides human review** workflow
- âœ… **Sends alerts** for high-harm content
- âœ… **Delivers clear explanations** (expert + "explain like I'm 12")

---

## ğŸ¯ Key Features

### AI-Powered Fact-Checking
- **Claim Detection Agent**: Identifies verifiable claims in text
- **Evidence Retrieval Agent**: Searches Google Fact Check API, NewsAPI, and more
- **Fact-Checker Agent**: GPT-4o/Claude powered reasoning with safety guardrails
- **Summarizer Agent**: Generates expert + child-friendly explanations

### Real-Time Analytics
- **FAISS Vector Search**: Similarity-based claim clustering
- **HDBSCAN Clustering**: Identifies trending misinformation topics
- **Harm Scoring**: 0-100 scale for content danger assessment

### Production-Ready Architecture
- **FastAPI Backend**: Async API with 8 endpoints
- **MongoDB**: Scalable NoSQL storage
- **Redis**: Caching and job queuing
- **React + Vite Frontend**: Modern, responsive UI
- **Docker Compose**: One-command deployment

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- OpenAI API key (required)
- NewsAPI key (optional but recommended)
- Google Fact Check API key (optional)

### 1. Clone & Configure

```bash
cd "untitled folder"
```

Copy environment variables:
```bash
cp .env.example .env
```

Edit `.env` and add your API keys:
```env
OPENAI_API_KEY=sk-your-key-here
NEWS_API_KEY=your-newsapi-key
GOOGLE_FACTCHECK_API_KEY=your-google-key
```

### 2. Launch with Docker

```bash
docker-compose up --build
```

This starts:
- **Backend API**: http://localhost:8000
- **Frontend UI**: http://localhost:5173
- **MongoDB**: localhost:27017
- **Redis**: localhost:6379

### 3. Access the Platform

Open your browser to:
- **Dashboard**: http://localhost:5173
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

---

## ğŸ“Š Architecture

```
CrisisGuard AI
â”‚
â”œâ”€â”€ Backend (Python + FastAPI)
â”‚   â”œâ”€â”€ AI Agents
â”‚   â”‚   â”œâ”€â”€ Claim Detector (GPT-4o)
â”‚   â”‚   â”œâ”€â”€ Evidence Retriever (Multi-source)
â”‚   â”‚   â”œâ”€â”€ Fact-Checker (LLM reasoning)
â”‚   â”‚   â””â”€â”€ Summarizer (Explanations)
â”‚   â”‚
â”‚   â”œâ”€â”€ Services
â”‚   â”‚   â”œâ”€â”€ Embedding Service (OpenAI + FAISS)
â”‚   â”‚   â””â”€â”€ Clustering Service (HDBSCAN)
â”‚   â”‚
â”‚   â”œâ”€â”€ Database
â”‚   â”‚   â”œâ”€â”€ MongoDB (Claims, Verdicts, Evidence)
â”‚   â”‚   â””â”€â”€ Redis (Cache, Queue)
â”‚   â”‚
â”‚   â””â”€â”€ API Routes
â”‚       â”œâ”€â”€ /api/ingest - Ingest text
â”‚       â”œâ”€â”€ /api/verify/{id} - Fact-check claim
â”‚       â”œâ”€â”€ /api/claims - List claims
â”‚       â”œâ”€â”€ /api/clusters - Trending topics
â”‚       â””â”€â”€ /api/alerts - High-harm alerts
â”‚
â””â”€â”€ Frontend (React + Vite + Tailwind)
    â”œâ”€â”€ Pages
    â”‚   â”œâ”€â”€ Dashboard (Stats + Overview)
    â”‚   â”œâ”€â”€ Claims List (Browse & Filter)
    â”‚   â”œâ”€â”€ Claim Detail (Full analysis)
    â”‚   â”œâ”€â”€ Trending Clusters
    â”‚   â”œâ”€â”€ Human Review Queue
    â”‚   â””â”€â”€ Alerts Panel
    â”‚
    â””â”€â”€ Components
        â”œâ”€â”€ ClaimCard
        â”œâ”€â”€ VerdictPill
        â”œâ”€â”€ EvidenceCard
        â””â”€â”€ Layout (Sidebar + TopNav)
```

---

## ğŸ”§ API Endpoints

### Core Endpoints

#### 1. Ingest Text
```bash
POST /api/ingest
Content-Type: application/json

{
  "text": "The moon landing was faked in 1969",
  "source": "https://example.com/post/123",
  "source_type": "social"
}
```

**Response:**
```json
{
  "claim_id": "507f1f77bcf86cd799439011",
  "is_claim": true,
  "message": "Claim detected and stored successfully",
  "claim_detected": {
    "id": "507f1f77bcf86cd799439011",
    "claim_text": "The moon landing was faked in 1969",
    "claim_type": "science",
    "confidence": 0.92
  }
}
```

#### 2. Verify Claim
```bash
POST /api/verify/507f1f77bcf86cd799439011
```

**Response:**
```json
{
  "verdict": "False",
  "confidence": 0.95,
  "reasoning": "Multiple authoritative sources confirm...",
  "sources": [
    {
      "link": "https://nasa.gov/...",
      "excerpt": "...",
      "reliability": 0.98
    }
  ],
  "explain_like_12": "People really did land on the moon...",
  "harm_score": 35,
  "recommended_action": "debunk"
}
```

#### 3. Get Claims
```bash
GET /api/claims?claim_type=health&status=verified&limit=20
```

#### 4. Get Trending Clusters
```bash
GET /api/clusters?limit=10
```

#### 5. Submit Feedback
```bash
POST /api/feedback
{
  "claim_id": "507f1f77bcf86cd799439011",
  "feedback_type": "correction",
  "content": "Additional evidence suggests..."
}
```

---

## ğŸ§ª Sample Workflow

### End-to-End Example

1. **Ingest a claim**:
```bash
curl -X POST http://localhost:8000/api/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Drinking bleach cures COVID-19",
    "source": "social_media_post",
    "source_type": "social"
  }'
```

2. **Verify the claim** (returns claim_id from step 1):
```bash
curl -X POST http://localhost:8000/api/verify/{claim_id}
```

3. **View in UI**:
   - Go to http://localhost:5173/claims
   - Click on the claim to see full analysis
   - Review verdict, evidence sources, and harm score

---

## ğŸ¨ Frontend Features

### Dashboard
- **Real-time stats**: Total claims, verified count, trending clusters
- **Verdict breakdown chart**: Visual distribution of True/False/Misleading
- **Recent claims feed**
- **One-click ingestion modal**

### Claim Detail Page
- **Full verdict analysis** with confidence score
- **Harm potential meter** (0-100 scale)
- **Expert reasoning** + "Explain like I'm 12"
- **Evidence sources** with reliability ratings
- **Similar claims** (vector similarity)
- **Community feedback** form

### Trending Clusters
- **Clustered claims** showing viral patterns
- **Trend score** visualization
- **Representative claim** for each cluster

### Human Review Queue
- **Approve/reject** AI verdicts
- **Override verdicts** with manual review
- **Add reviewer notes**

### Alerts Panel
- **High-harm claim alerts** (score â‰¥ 70)
- **Severity filtering** (Critical/High/Medium/Low)
- **Resolve alerts** workflow

---

## ğŸ” Safety & Ethics

### Built-in Guardrails

1. **No Hallucinated Citations**
   - LLM can only cite sources from provided evidence
   - Validation ensures URLs match retrieved evidence

2. **Harm Scoring**
   - 0-20: Harmless
   - 21-40: Minor misinformation
   - 41-60: Moderate potential harm
   - 61-80: Significant harm (health, safety, democracy)
   - 81-100: Crisis-level (violence incitement, public health emergency)

3. **Transparency**
   - All reasoning is logged
   - Human review required for publication
   - Confidence scores displayed

4. **Evidence Quality**
   - Reliability scoring for all sources
   - Preference for gov/academic/fact-check sites
   - Cross-referencing multiple sources

---

## ğŸ“ Project Structure

```
untitled folder/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ claim_detector.py
â”‚   â”‚   â”œâ”€â”€ evidence_retriever.py
â”‚   â”‚   â”œâ”€â”€ fact_checker.py
â”‚   â”‚   â””â”€â”€ prompts.py
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ connection.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ claims.py
â”‚   â”‚   â”œâ”€â”€ verification.py
â”‚   â”‚   â”œâ”€â”€ clusters.py
â”‚   â”‚   â”œâ”€â”€ feedback.py
â”‚   â”‚   â””â”€â”€ alerts.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â””â”€â”€ clustering_service.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ client.js
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Layout.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TopNav.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ClaimCard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ VerdictPill.jsx
â”‚   â”‚   â”‚   â””â”€â”€ EvidenceCard.jsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ClaimsList.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ClaimDetail.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TrendingClusters.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ HumanReview.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Alerts.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.11** - Modern async Python
- **FastAPI** - High-performance web framework
- **MongoDB** - Flexible document database
- **Redis** - Caching & job queue
- **FAISS** - Vector similarity search
- **OpenAI GPT-4o** - LLM reasoning
- **HDBSCAN** - Clustering algorithm

### Frontend
- **React 18** - UI framework
- **Vite** - Lightning-fast build tool
- **Tailwind CSS** - Utility-first styling
- **Recharts** - Data visualization
- **React Router** - Navigation
- **Axios** - HTTP client

### Infrastructure
- **Docker** - Containerization
- **Docker Compose** - Multi-service orchestration
- **Uvicorn** - ASGI server

---

## ğŸ“ˆ Performance

- **Claim Detection**: ~2-3 seconds
- **Full Verification**: ~10-15 seconds (depends on evidence retrieval)
- **Clustering**: Batch process (every 1-24 hours)
- **API Response Time**: <500ms for most endpoints

---

## ğŸ§© Extensibility

### Adding New Evidence Sources

Edit `backend/agents/evidence_retriever.py`:

```python
async def _search_custom_source(self, query: str):
    # Add your custom API integration
    async with httpx.AsyncClient() as client:
        response = await client.get(f"https://api.example.com?q={query}")
        # Parse and return sources
```

### Custom Claim Types

Edit `backend/models/schemas.py`:

```python
claim_type: str = Field(
    default="general", 
    regex="^(health|politics|general|science|business|YOUR_TYPE)$"
)
```

### Alternative LLMs

Edit `backend/agents/fact_checker.py` to use Claude, Llama, etc.:

```python
from anthropic import AsyncAnthropic

self.client = AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
```

---

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Check logs
docker-compose logs backend

# Rebuild
docker-compose down
docker-compose up --build
```

### MongoDB connection failed
```bash
# Verify MongoDB is running
docker-compose ps

# Reset volumes
docker-compose down -v
docker-compose up
```

### Frontend not loading
```bash
# Check if backend is accessible
curl http://localhost:8000/health

# Rebuild frontend
cd frontend
npm install
npm run dev
```

---

## ğŸ“ License

MIT License - See LICENSE file for details

---

## ğŸ‘¥ Contributing

This is a hackathon project built for demonstration. For production use:

1. Add authentication & authorization
2. Implement rate limiting
3. Add comprehensive error handling
4. Set up monitoring (Sentry, DataDog, etc.)
5. Add unit & integration tests
6. Configure CI/CD pipelines
7. Use production-grade LLM API keys

---

## ğŸ‰ Acknowledgments

- **OpenAI** - GPT-4o API
- **NewsAPI** - News article search
- **Google** - Fact Check Tools API
- **FAISS** - Vector similarity search
- **React** - UI framework
- **FastAPI** - Web framework

---

## ğŸ“ Support

For questions or issues:
- Create a GitHub issue
- Review API documentation at http://localhost:8000/docs
- Check Docker logs: `docker-compose logs -f`

---

**Built with â¤ï¸ for fighting misinformation**

*"The best way to fight misinformation is with better information."*
