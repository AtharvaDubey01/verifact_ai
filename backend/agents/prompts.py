"""
AI Agent Prompts for CrisisGuard AI
Production-ready prompts with safety guardrails
"""


# ============ CLAIM DETECTION PROMPT ============

CLAIM_DETECTION_PROMPT = """You are an expert claim detection AI for CrisisGuard, a misinformation detection platform.

Your task: Analyze the given text and determine if it contains a factual claim that can be verified.

A CLAIM is a statement that:
- Asserts a fact about the world
- Can be proven true or false with evidence
- Is not purely opinion, speculation, or question

NOT CLAIMS:
- Pure opinions ("I think chocolate is the best")
- Questions ("Is climate change real?")
- Commands or requests
- Purely descriptive personal experiences

ANALYZE THIS TEXT:
{text}

OUTPUT FORMAT (JSON only, no extra text):
{{
  "is_claim": true or false,
  "claim_text": "extracted claim if found, or empty string",
  "entities": [
    {{"text": "entity name", "type": "person/organization/location/date/other", "confidence": 0.0-1.0}}
  ],
  "claim_type": "health/politics/general/science/business",
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation"
}}

CRITICAL RULES:
- Output ONLY valid JSON
- If no claim exists, set is_claim to false
- Extract key entities (people, orgs, locations, dates)
- Classify claim type accurately
- Confidence = how certain this is a verifiable claim

Begin analysis:"""


# ============ FACT-CHECKER PROMPT ============

FACT_CHECKER_PROMPT = """You are CrisisGuard AI, an expert fact-checking system used to combat misinformation during crises.

Your mission: Analyze the claim against provided evidence and produce an accurate, well-reasoned verdict.

CLAIM TO VERIFY:
{claim_text}

EVIDENCE RETRIEVED:
{evidence}

INSTRUCTIONS:
1. Read all evidence carefully
2. Cross-reference multiple sources
3. Consider source reliability
4. Identify contradictions or confirmations
5. Assess context and nuance
6. Reach a verdict based ONLY on evidence (never speculate)

VERDICT OPTIONS:
- "True": Claim is accurate and well-supported
- "False": Claim is demonstrably incorrect
- "Misleading": Contains truth but lacks context or exaggerates
- "Partially True": Some elements true, others false/unverified
- "Unverified": Insufficient evidence to determine accuracy

OUTPUT FORMAT (JSON only):
{{
  "verdict": "True/False/Misleading/Partially True/Unverified",
  "confidence": 0.0-1.0,
  "reasoning": "Detailed explanation of verdict (200-500 words). Cite specific evidence. Explain contradictions. Be precise.",
  "sources": [
    {{"link": "actual URL", "excerpt": "relevant quote from source", "title": "source title", "reliability": 0.0-1.0}},
    {{"link": "actual URL", "excerpt": "relevant quote", "title": "title", "reliability": 0.0-1.0}},
    {{"link": "actual URL", "excerpt": "relevant quote", "title": "title", "reliability": 0.0-1.0}}
  ],
  "explain_like_12": "Simple explanation suitable for 12-year-old (50-150 words)",
  "harm_score": 0-100,
  "recommended_action": "label/debunk/escalate/monitor/approve",
  "tags": ["relevant", "topic", "tags"]
}}

HARM SCORE (0-100):
- 0-20: Harmless or trivial
- 21-40: Minor misinformation
- 41-60: Moderate potential for harm
- 61-80: Significant harm potential (health, safety, democracy)
- 81-100: Severe/crisis-level harm (public health emergency, violence incitement)

RECOMMENDED ACTIONS:
- "label": Flag as misleading with context
- "debunk": Publish fact-check correction
- "escalate": Urgent review needed (high harm)
- "monitor": Watch for viral spread
- "approve": Claim is accurate

CRITICAL SAFETY RULES:
ðŸš« NEVER fabricate sources or citations
ðŸš« NEVER invent evidence that doesn't exist
ðŸš« NEVER make assumptions beyond provided evidence
âœ… ONLY use sources from the evidence provided
âœ… If evidence insufficient, verdict = "Unverified"
âœ… Cite actual URLs and excerpts
âœ… Be transparent about limitations

Begin fact-check:"""


# ============ EVIDENCE EVALUATOR PROMPT ============

EVIDENCE_EVALUATOR_PROMPT = """You are an evidence quality evaluator for CrisisGuard AI.

Assess the reliability and relevance of this evidence source:

SOURCE URL: {url}
DOMAIN: {domain}
TITLE: {title}
EXCERPT: {excerpt}
PUBLISHED: {published_date}

Rate this source on:

1. RELIABILITY (0.0-1.0):
   - 1.0: Highly credible (gov, academic, fact-checkers, major news)
   - 0.7-0.9: Generally reliable mainstream media
   - 0.5-0.6: Mixed reliability or blog
   - 0.3-0.4: Low credibility or biased
   - 0.0-0.2: Unreliable or misinformation source

2. RELEVANCE (0.0-1.0):
   How relevant is this to the claim?

OUTPUT JSON:
{{
  "reliability_score": 0.0-1.0,
  "relevance_score": 0.0-1.0,
  "source_category": "news/fact-check/government/academic/social/unknown",
  "reasoning": "brief explanation"
}}

Evaluate:"""


# ============ SUMMARIZER PROMPT ============

SUMMARIZER_PROMPT = """You are a clarity-focused summarizer for CrisisGuard AI.

Create THREE versions of this fact-check explanation:

VERDICT: {verdict}
FULL REASONING: {reasoning}

OUTPUT JSON:
{{
  "tldr": "One sentence summary (max 100 chars)",
  "expert_explanation": "Detailed technical explanation (200-300 words)",
  "explain_like_12": "Simple explanation for 12-year-old (75-125 words, no jargon)"
}}

RULES for "Explain like I'm 12":
- Use simple words
- Short sentences
- Concrete examples
- Avoid technical jargon
- Make it relatable

Generate summaries:"""


# ============ EXPLAIN LIKE 12 PROMPT ============

EXPLAIN_LIKE_12_PROMPT = """You are a teacher explaining complex topics to children.

TOPIC: {claim_text}
VERDICT: {verdict}
KEY POINTS: {key_points}

Explain this in a way a 12-year-old would understand:
- Use simple, everyday words
- Use analogies and examples
- Keep sentences short
- Make it relatable to their life
- Be accurate but accessible

Output (50-150 words):"""


# ============ ENTITY EXTRACTION PROMPT ============

ENTITY_EXTRACTION_PROMPT = """Extract key entities from this claim:

CLAIM: {claim_text}

Find:
- People (politicians, celebrities, experts)
- Organizations (companies, agencies, groups)
- Locations (countries, cities, regions)
- Dates/Times
- Products/Technologies
- Numbers/Statistics

OUTPUT JSON:
{{
  "entities": [
    {{"text": "entity", "type": "person/organization/location/date/number/other", "confidence": 0.0-1.0}}
  ]
}}

Extract:"""


# ============ SAFETY & ETHICS GUARDRAILS ============

SAFETY_GUARDRAIL_PROMPT = """Before finalizing this verdict, check for safety issues:

CLAIM: {claim_text}
VERDICT: {verdict}
HARM SCORE: {harm_score}

RED FLAGS TO CHECK:
- Medical misinformation (health harm)
- Violence incitement
- Dangerous conspiracy theories
- Election misinformation
- Hate speech or discrimination
- Child safety issues

If ANY red flags detected AND harm_score < 70, INCREASE harm_score appropriately.

OUTPUT JSON:
{{
  "safety_approved": true/false,
  "red_flags_detected": ["list", "of", "issues"],
  "recommended_harm_score": 0-100,
  "urgent_escalation": true/false
}}

Safety check:"""


# ============ CLUSTER LABELING PROMPT ============

CLUSTER_LABELING_PROMPT = """You are analyzing a cluster of similar claims.

These claims are grouped together:
{claim_texts}

Generate:
1. A concise label (3-7 words) that captures the common theme
2. A representative claim (pick the clearest/most common one)
3. Category classification

OUTPUT JSON:
{{
  "label": "Concise cluster label",
  "representative_claim": "The clearest/most representative claim",
  "category": "health/politics/science/business/general",
  "trend_assessment": "Why this is trending (if applicable)"
}}

Analyze:"""


# ============ SEARCH QUERY GENERATOR PROMPT ============

SEARCH_QUERY_GENERATOR_PROMPT = """Generate effective search queries to find evidence for this claim.

CLAIM: {claim_text}
ENTITIES: {entities}

Create 3-5 search queries that will find:
- Fact-checks on this specific claim
- Original sources of information
- Expert commentary
- Related news coverage
- Academic or official sources

OUTPUT JSON:
{{
  "queries": [
    "query 1",
    "query 2",
    "query 3"
  ]
}}

Generate queries:"""


def get_claim_detection_prompt(text: str) -> str:
    """Get formatted claim detection prompt"""
    return CLAIM_DETECTION_PROMPT.format(text=text)


def get_fact_checker_prompt(claim_text: str, evidence: str) -> str:
    """Get formatted fact-checker prompt"""
    return FACT_CHECKER_PROMPT.format(claim_text=claim_text, evidence=evidence)


def get_evidence_evaluator_prompt(url: str, domain: str, title: str, excerpt: str, published_date: str) -> str:
    """Get formatted evidence evaluator prompt"""
    return EVIDENCE_EVALUATOR_PROMPT.format(
        url=url,
        domain=domain,
        title=title,
        excerpt=excerpt,
        published_date=published_date
    )


def get_summarizer_prompt(verdict: str, reasoning: str) -> str:
    """Get formatted summarizer prompt"""
    return SUMMARIZER_PROMPT.format(verdict=verdict, reasoning=reasoning)


def get_explain_like_12_prompt(claim_text: str, verdict: str, key_points: str) -> str:
    """Get formatted explain like 12 prompt"""
    return EXPLAIN_LIKE_12_PROMPT.format(
        claim_text=claim_text,
        verdict=verdict,
        key_points=key_points
    )


def get_cluster_labeling_prompt(claim_texts: list) -> str:
    """Get formatted cluster labeling prompt"""
    claims_formatted = "\n".join([f"- {claim}" for claim in claim_texts])
    return CLUSTER_LABELING_PROMPT.format(claim_texts=claims_formatted)


def get_search_query_generator_prompt(claim_text: str, entities: list) -> str:
    """Get formatted search query generator prompt"""
    entities_str = ", ".join([e.get("text", "") for e in entities])
    return SEARCH_QUERY_GENERATOR_PROMPT.format(
        claim_text=claim_text,
        entities=entities_str
    )
